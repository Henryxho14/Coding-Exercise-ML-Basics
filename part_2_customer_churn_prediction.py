# -*- coding: utf-8 -*-
"""Part 2: Customer Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13iQ8E7JY8N03xx_-478dy0k_6cChnOgT
"""

import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# ------------------------------------------------------------
# REALISTIC DATA SOURCE (100+ records):
# Kaggle: "Telco Customer Churn" (IBM sample telecom churn dataset)
# https://www.kaggle.com/datasets/blastchar/telco-customer-churn
#
# Label:
# - Churn ("Yes"/"No") -> churn (1/0)
# ------------------------------------------------------------

FILE_PATH = "/content/WA_Fn-UseC_-Telco-Customer-Churn 2.csv"  # <-- update to your local path

# ----------------------------
# Load dataset
# ----------------------------
df_raw = pd.read_csv(FILE_PATH)

if len(df_raw) < 100:
    raise ValueError("Dataset must have 100+ records.")

# ----------------------------
# Select features + label
# ----------------------------
numeric_features = ["tenure", "MonthlyCharges", "TotalCharges", "SeniorCitizen"]
categorical_features = [
    "gender", "Partner", "Dependents",
    "PhoneService", "InternetService",
    "Contract", "PaymentMethod", "PaperlessBilling"
]

required_cols = numeric_features + categorical_features + ["Churn"]
missing = [c for c in required_cols if c not in df_raw.columns]
if missing:
    raise ValueError(f"Missing expected columns: {missing}\nFound columns: {df_raw.columns.tolist()}")

df = df_raw[required_cols].copy()

# TotalCharges can contain blanks stored as strings; convert safely
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

# Create churn label: 1 = churn, 0 = no churn
df["churn"] = df["Churn"].map({"Yes": 1, "No": 0})
if df["churn"].isna().any():
    raise ValueError("Unexpected values in Churn column; expected 'Yes'/'No'.")

X = df[numeric_features + categorical_features]
y = df["churn"]

# ----------------------------
# Preprocessing:
# - StandardScaler for numeric
# - OneHotEncoder for categorical
# - Imputation so the pipeline runs without errors
# ----------------------------
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

# ----------------------------
# Logistic Regression model
# ----------------------------
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", LogisticRegression(random_state=42, max_iter=2000))
])

# Split + train
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
model.fit(X_train, y_train)

# ----------------------------
# Predict churn probability + threshold classification
# ----------------------------
new_customer = pd.DataFrame({
    "tenure": [12],
    "MonthlyCharges": [75.35],
    "TotalCharges": [900.00],
    "SeniorCitizen": [0],
    "gender": ["Female"],
    "Partner": ["Yes"],
    "Dependents": ["No"],
    "PhoneService": ["Yes"],
    "InternetService": ["Fiber optic"],
    "Contract": ["Month-to-month"],
    "PaymentMethod": ["Electronic check"],
    "PaperlessBilling": ["Yes"]
})

# predict_proba returns [P(class=0), P(class=1)] for each row
churn_probability = model.predict_proba(new_customer)[0][1]  # P(churn=1)
threshold = 0.5
churn_prediction = 1 if churn_probability >= threshold else 0

print(f"Churn Probability for new customer (P(churn=1)): {churn_probability:.2f}")
print(f"Churn Classification using threshold {threshold}: {churn_prediction} (1=at-risk, 0=not-at-risk)")

# ----------------------------
# Expanded explanation: probability, threshold, and business use
# ----------------------------
print("\nDetailed Explanation:")

print(
    "1) What the churn probability means:\n"
    f"   - The model outputs a probability between 0 and 1 for churn (class 1).\n"
    f"   - Example: {churn_probability:.2f} means the model estimates about a "
    f"{churn_probability*100:.0f}% chance that this customer will churn.\n"
    "   - This is NOT a guarantee; it is a risk score based on patterns learned from historical data."
)

print(
    "\n2) What the 0.5 threshold means:\n"
    f"   - A threshold is the cutoff used to convert a probability into a class label.\n"
    f"   - If probability >= {threshold}, we label the customer as 'at risk' (churn=1).\n"
    f"   - If probability < {threshold}, we label the customer as 'not at risk' (churn=0).\n"
    "   - The threshold can be adjusted depending on business goals:\n"
    "     • Lower threshold (e.g., 0.3) flags more customers (higher recall) but may create more false alarms.\n"
    "     • Higher threshold (e.g., 0.7) flags fewer customers (higher precision) but may miss some churners."
)

print(
    "\n3) How businesses use churn predictions to reduce churn:\n"
    "   - Prioritize outreach: customer success teams contact high-risk customers first.\n"
    "   - Targeted offers: discounts, plan changes, or upgrades for customers likely to leave.\n"
    "   - Service interventions: faster support, proactive troubleshooting, or training for low-usage customers.\n"
    "   - Product improvements: identify features/segments associated with churn and improve the experience.\n"
    "   - Budget efficiency: focus retention spend where it has the best ROI (highest churn risk and customer value)."
)